# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gMttDQWH1HzVFqNkzcJEzG10RXiHCm-n
"""

!pip install gtts

!pip install easyocr

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import numpy as np
from tensorflow.keras.applications import VGG16
import easyocr
from IPython.display import display, HTML , Audio
from google.colab import output , drive , auth
from PIL import Image
import base64
import io
import os
import cv2
from gtts import gTTS
import zipfile

zip_path = '/content/medicine_data.zip'
print(f"zip_path: {zip_path}")

if os.path.exists(zip_path):
    print("File exists at the specified path.")
else:
    print("File not found. Please check the path.")
       # If the file doesn't exist, you need to upload or download the correct file to the specified location.

   # Rest of the code for extracting the ZIP file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
       zip_ref.extractall('/content/medicine_data')
       dataset_path = '/content/medicine_data'

# Paths to the dataset directories
train_dir = '/content/medicine_data/medicine_data'
val_dir = '/content/medicine_data/medicine_data'

# Parameters
batch_size = 32
img_height = 224
img_width = 224

# Load the datasets
train_dataset = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

val_dataset = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)


# Rescale validation data
validation_datagen = ImageDataGenerator(rescale=1.0/255)

# Create generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'  # Use 'binary' for binary classification
)


validation_generator = validation_datagen.flow_from_directory(
   val_dir,
   target_size=(224, 224),
   batch_size=32,
   class_mode='categorical'
)

# Load pre-trained VGG16 model without the top layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of the base model
base_model.trainable = False

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),


    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),


    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')
])
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Summary of the model
model.summary()

history=model.fit(train_generator,epochs=25,validation_data=validation_generator)

# Unfreeze some layers of the base model
base_model.trainable = True
for layer in base_model.layers[:15]:  # Freeze the first 15 layers
    layer.trainable = False

# Recompile the model with a lower learning rate
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history=model.fit(train_generator,epochs=25,validation_data=validation_generator)

auth.authenticate_user()

# Mount Google Drive
drive.mount('/content/drive',force_remount=True)

# Define path to save model
model_path = "/content/drive/MyDrive/medicine_detection_model.h5"

# Save model
model.save(model_path)
print(f"Model saved to {model_path}")

# to load the model
drive.mount('/content/drive')

model_path = "/content/drive/MyDrive/medicine_detection_model.h5"
model = tf.keras.models.load_model(model_path)

print("Model loaded successfully!")

# accuracy = history.history['accuracy'][-1]
# print(f"Final Training Accuracy: {accuracy}")
loss , accuracy  = model.evaluate(validation_generator)
print(f"Final Validation Loss: {loss}")
print(f"Final Validation Accuracy: {accuracy}")

# List of medicine names to detect
medicines_list = ['Amlodipine', 'Amoxicillin',  'Atorvastatin',
                  'Ciprofloxacin', 'Ibuprofen', 'Lisinopril', 'Losartan',
                  'Metformin', 'Omeprazole', 'Paracetamol', 'Sertraline']

# 2) OCR list (we add "amoxycillin" so it can match text on the box)
ocr_list = medicines_list + ["amoxycillin"]

# Dictionary containing medicine names and their information
medicines_info = {
    "Amlodipine": "Amlodipine is a calcium channel blocker used to treat high blood pressure and angina by relaxing blood vessels and improving blood flow. It helps reduce the risk of heart attacks and strokes. Common side effects include dizziness, swelling, and fatigue.",
    "Amoxicillin": "Amoxicillin is a broad-spectrum antibiotic used to treat bacterial infections, including respiratory, ear, throat, and urinary tract infections. It works by stopping bacterial growth. Common side effects include nausea, diarrhea, and rash.",
    "Amoxycillin": "Amoxycillin is another name for Amoxicillin, Amoxycillin  is a penicillin-type antibiotic used to treat bacterial infections like respiratory, ear, throat, and urinary tract infections. It works by inhibiting bacterial growth. Common side effects include nausea, diarrhea, and skin rash.",
    "Atorvastatin": "Atorvastatin is a statin medication used to lower cholesterol and reduce the risk of heart disease and stroke. It works by blocking cholesterol production in the liver. Common side effects include muscle pain, fatigue, and digestive issues.",
    "Ciprofloxacin": "Ciprofloxacin is a fluoroquinolone antibiotic used to treat bacterial infections such as urinary tract infections, respiratory infections, and gastrointestinal infections. It works by inhibiting bacterial DNA replication. Common side effects include nausea, diarrhea, and dizziness.",
    "Ibuprofen": "Ibuprofen is a nonsteroidal anti-inflammatory drug (NSAID) used to reduce pain, fever, and inflammation in conditions like headaches, muscle pain, arthritis, and menstrual cramps. Common side effects include stomach upset, nausea, and dizziness.",
    "Lisinopril": "Lisinopril is an ACE inhibitor used to treat high blood pressure and heart failure and to improve survival after a heart attack. It works by relaxing blood vessels to lower blood pressure. Common side effects include dizziness, cough, and fatigue.",
    "Losartan": "Losartan is an angiotensin II receptor blocker (ARB) used to treat high blood pressure and protect the kidneys in diabetic patients. It helps relax blood vessels, lowering blood pressure. Common side effects include dizziness, fatigue, and low blood pressure.",
    "Metformin": "Metformin is an oral antidiabetic medication used to manage type 2 diabetes by lowering blood sugar levels and improving insulin sensitivity. Common side effects include nausea, diarrhea, and stomach upset.",
    "Omeprazole": "Omeprazole is a proton pump inhibitor (PPI) used to treat acid reflux, ulcers, and GERD by reducing stomach acid production. Common side effects include headache, nausea, and stomach pain.",
    "Paracetamol": "Paracetamol (Acetaminophen) is a pain reliever and fever reducer used for headaches, muscle pain, colds, and fever. Common side effects are rare but may include nausea or liver damage with high doses.",
    "Sertraline": "Sertraline is a selective serotonin reuptake inhibitor (SSRI) used to treat depression, anxiety, OCD, and PTSD by increasing serotonin levels in the brain. Common side effects include nausea, dizziness, dry mouth, and insomnia."
}

# Convert medicine names to lowercase for case-insensitive comparison
medicines_list = [med.lower() for med in medicines_list]
ocr_list = [med.lower() for med in ocr_list]

# Initialize a list to track boxes that have already been drawn
drawn_boxes = []
audio_file_to_play = None



# Define the target size for image preprocessing
TARGET_SIZE = (224, 224)

# Function to generate and return audio for a detected medicine
def generate_medicine_audio(medicine_name):
    for med in medicines_info:
        if med.lower() in medicine_name.lower():  # Check for partial matches
            text = medicines_info[med]
            tts = gTTS(text=text, lang='en')

            # Save audio file in a directory within /content/
            audio_path = f"/content/audio/{med}.mp3"
            os.makedirs(os.path.dirname(audio_path), exist_ok=True)  # Ensure the directory exists
            tts.save(audio_path)
            return audio_path

# Preprocess the uploaded image
def preprocess_image(image_data, target_size=(224, 224)):
    # Decode Base64 string to bytes
    image_data = base64.b64decode(image_data.split(",")[1])
    # Load image using PIL
    image = Image.open(io.BytesIO(image_data)).convert("RGB")
    # Resize image to the model's input size
    image = image.resize(target_size)
    # Convert image to numpy array
    image_array = np.array(image)
    # Normalize pixel values (0 to 1)
    image_array = image_array / 255.0
    # Add a batch dimension (1, height, width, channels)
    image_array = np.expand_dims(image_array, axis=0)
    return image_array

# Function to handle image upload and prediction
def upload_image(image_data):
    try:
        print("Received image data.")

        # Define the save path
        save_path = "/content/uploaded_image.jpg"

        # Decode Base64 string to bytes
        image_bytes = base64.b64decode(image_data.split(",")[1])
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        image.save(save_path)

        # Ensure the file exists
        if not os.path.exists(save_path):
            raise FileNotFoundError(f"Image not found at {save_path}")

        print(f"Image saved at: {save_path}")
        # Initialize EasyOCR Reader
        reader = easyocr.Reader(['en'], gpu=False)
        # Load image as numpy array
        image_np = np.array(image)

        # Perform OCR
        text_ = reader.readtext(image_np)
        found_medicine = None
        threshold = 0.15

        for bbox, detected_text, score in text_:
            detected_text_cleaned = detected_text.strip().lower()
            if detected_text_cleaned in ocr_list and score > threshold:
                found_medicine = detected_text_cleaned
                print(f"✅ Medicine Found: {found_medicine}")
                break  # Stop after finding the first match


        # Read image using OpenCV
        img = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)  # Convert PIL image to OpenCV format

        if not found_medicine:
            print("❌ No medicine found in OCR. Skipping prediction.")
            return
        
        # Preprocess the image
        print("Preprocessing the image...")
        preprocessed_image = preprocess_image(image_data, TARGET_SIZE)
        print(f"Preprocessed image shape: {preprocessed_image.shape}")

        # Make a prediction
        print("Making a prediction...")
        predictions = model.predict(preprocessed_image)
        print(f"Raw predictions: {predictions}")

        # Decode predictions
        predicted_class_index = np.argmax(predictions[0])  # predictions is a list of lists, we need the inner list
        class_labels = ocr_list  # Use predefined medicine list
        predicted_class_label = class_labels[predicted_class_index]

        # Display the result (Directly show the image and prediction)
        plt.imshow(image)
        plt.axis('off')
        plt.title(f"Predicted Class: {predicted_class_label.capitalize()} (Confidence: {np.max(predictions):.2%})")
        plt.show()

        # Iterate over each detected text
        for t_, t in enumerate(text_):
            bbox, detected_text, score = t  # Extract bounding box, text, and confidence score

            # Normalize text (remove extra spaces, convert to lowercase)
            detected_text_cleaned = detected_text.strip().lower()

            # Print detected text and confidence for debugging
            print(f"Detected Text: {detected_text} | Confidence: {score:.2%}")

            # Check if detected text contains any of the medicine names (partial match)
            for med in ocr_list:
                if med in detected_text_cleaned and score > threshold:
                    print(f"✅ Medicine Found: {detected_text}")

                    # Convert bounding box points to integers (this should fix the issue with the box)
                    top_left = tuple(map(int, bbox[0]))  # Top-left corner
                    bottom_right = tuple(map(int, bbox[2]))  # Bottom-right corner

                    # Ensure that the box has not been drawn before
                    if (top_left, bottom_right) not in drawn_boxes:
                        # Draw a rectangle around the detected text using the bounding box coordinates
                        cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 5)

                        # Overlay the detected text on the image
                        cv2.putText(
                            img,  # The image to draw on
                            detected_text,  # The text to display
                            top_left,  # Position of the text
                            cv2.FONT_HERSHEY_COMPLEX, 0.65,  # Font type & scale
                            (255, 0, 0), 2  # Text color & thickness
                        )

                        # Add this box to the list of drawn boxes to avoid duplicates
                        drawn_boxes.append((top_left, bottom_right))

                        # Generate audio for the detected medicine
                        audio_file_to_play = generate_medicine_audio(med)
                        break  # No need to check further once a match is found

        # Convert the BGR image to RGB (as OpenCV loads images in BGR format)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Display the image with boxes
        plt.imshow(img_rgb)
        plt.axis('off')  # Hide axes for a cleaner display
        plt.show()

        # Display the audio button after the image
        if audio_file_to_play:
            display(Audio(audio_file_to_play, autoplay=True))  # Play the generated audio

        return save_path

    except Exception as e:
        print(f"Error during processing: {e}")

# Register the function for JavaScript callback
output.register_callback('notebook.upload_image', upload_image)

# HTML and JavaScript for uploading and handling image files
def upload_image_page():
    upload_html = """
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f7f7f7;
            margin: 0;
            padding: 0;
        }
        .container {
            max-width: 600px;
            margin: 50px auto;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            text-align: center;
        }
        h1 {
            font-size: 24px;
            color: #333;
        }
        p {
            font-size: 16px;
            color: #666;
        }
        .upload-btn {
            display: inline-block;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 14px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: #ffffff;
            text-decoration: none;
            text-align: center;
        }
        .upload-btn:hover {
            background-color: #0056b3;
        }
        input[type="file"] {
            display: none;
        }
        label[for="file-upload"] {
            display: inline-block;
            margin: 20px auto;
            padding: 12px 24px;
            font-size: 16px;
            font-weight: bold;
            background-color: #28a745;
            color: white;
            border-radius: 5px;
            cursor: pointer;
            border: none;
            text-align: center;
        }
        label[for="file-upload"]:hover {
            background-color: #218838;
        }
        #remove-button {
            display: none;
            margin: 20px auto;
            padding: 10px 20px;
            font-size: 16px;
            background-color: #dc3545;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            text-align: center;
        }
        #remove-button:hover {
            background-color: #c82333;
        }
         #output-messages {
        margin-top: 20px;
        padding: 10px;
        background-color: #eef2ff;
        border-left: 5px solid #007bff;
        border-radius: 5px;
        text-align: left;
        font-size: 14px;
        color: #333;
        display: none; /* Initially hidden */
    }
    </style>
    <div class="container">
        <h1>Image Upload and Prediction</h1>
        <p>Click the button below to upload an image file:</p>
        <label for="file-upload">Upload File</label>
        <input type="file" id="file-upload" onchange="handleUpload(event)">
        <div id="image-container"></div>
        
    </div>
    <script>
        function handleUpload(event) {
            var file = event.target.files[0];
            if (file) {
                var reader = new FileReader();
                reader.onload = function(e) {
                    var imageContainer = document.getElementById('image-container');
                    imageContainer.innerHTML = ""; // Clear previous image
                    var imgElement = document.createElement("img");
                    imgElement.src = e.target.result;
                    imgElement.style.maxWidth = "100%";
                    imgElement.style.maxHeight = "400px";
                    imageContainer.appendChild(imgElement);

                   // Pass the image data to the Python environment
                google.colab.kernel.invokeFunction('notebook.upload_image', [e.target.result], {})
                    .catch(err => alert("Error processing image: " + err));


                };
                reader.readAsDataURL(file);
            }
        }

        
    </script>
    """
    display(HTML(upload_html))

# Show the upload page
upload_image_page()

